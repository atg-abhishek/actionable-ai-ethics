

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI Safety, Security, and Stability Among Great Powers &#8212; Actionable AI Ethics</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Disability, Bias, and AI" href="disability_bias_ai.html" />
    <link rel="prev" title="“Cool Projects” or “Expanding the Efficiency of the Murderous American War Machine?”" href="american_war_machine.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/abhishek.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Actionable AI Ethics</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Welcome to Actionable AI Ethics
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 current active">
  <a class="reference internal" href="readings.html">
   Readings
  </a>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="reference internal" href="papers.html">
     Papers
    </a>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="fairness_definitions_explained.html">
       Fairness Definitions Explained
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="automating_informality.html">
       Automating informality: On AI and labour in the global South
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="hazard_modes.html">
       Hazard Contribution Modes of Machine Learning Components
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="lets_talk_privacy.html">
       Project Let’s Talk Privacy Full Report
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="american_war_machine.html">
       “Cool Projects” or “Expanding the Efficiency of the Murderous American War Machine?”
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       AI Safety, Security, and Stability Among Great Powers
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="disability_bias_ai.html">
       Disability, Bias, and AI
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="books.html">
     Books
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tools.html">
   AI Ethics Tool of the Week
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/ai_safety_great_powers.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-line-summary">
     One-line summary
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-are-some-of-the-key-problems">
     What are some of the key problems?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-do-we-create-pragmatic-engagement">
     How do we create pragmatic engagement?
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#what-is-track-1-5-and-track-2">
       What is Track 1.5 and Track 2?
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#actions-that-people-can-take">
     Actions that people can take
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#open-sky-revival-for-ai-systems">
     Open sky revival for AI systems
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#better-communication">
     Better communication
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lessons-learned">
     Lessons learned
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusion">
     Conclusion
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-does-this-mean-for-actionable-ai-ethics">
     What does this mean for Actionable AI Ethics?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#questions-that-i-am-exploring">
     Questions that I am exploring
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#potential-further-reading">
     Potential further reading
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#twitter-discussion">
     Twitter discussion
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sign-up-for-the-newsletter">
     Sign up for the newsletter
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support-me-with-a-coffee">
     Support me with a coffee
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="ai-safety-security-and-stability-among-great-powers">
<h1>AI Safety, Security, and Stability Among Great Powers<a class="headerlink" href="#ai-safety-security-and-stability-among-great-powers" title="Permalink to this headline">¶</a></h1>
<p><strong>Authors</strong>: Andrew Imbrie and Elsa B. Kania</p>
<p><a class="reference external" href="https://cset.georgetown.edu/research/ai-safety-security-and-stability-among-great-powers-options-challenges-and-lessons-learned-for-pragmatic-engagement/">Paper link</a></p>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<div class="section" id="one-line-summary">
<h3>One-line summary<a class="headerlink" href="#one-line-summary" title="Permalink to this headline">¶</a></h3>
<p>The paper takes a critical view of the international relationships between countries that have advanced AI capabilities and makes recommendations for grounding discussions on AI capabilities, limitations, and harms through piggybacking on traditional avenues of transnational negotiation and policy-making. Instead of perceiving AI development as an arms race, it advocates for the view of cooperation to ensure a more secure future as this technology becomes more widely deployed, especially in military applications.</p>
<iframe src="https://actionableaiethics.substack.com/embed" width="480" height="320" style="border:1px solid #EEE; background:white;" frameborder="0" scrolling="no"></iframe>
<p>If you enjoy the content on this page, you can support my work by <a class="reference external" href="https://buymeacoffee.com/abhishekgupta">buying me a coffee</a></p>
<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="abhishekgupta" data-color="#FF5F5F" data-emoji=""  data-font="Cookie" data-text="Buy me a coffee" data-outline-color="#000000" data-font-color="#ffffff" data-coffee-color="#FFDD00" ></script>
</div>
<div class="section" id="what-are-some-of-the-key-problems">
<h3>What are some of the key problems?<a class="headerlink" href="#what-are-some-of-the-key-problems" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Unsurprisingly, given the popularity of AI, military leaders are often excited by the potential of deploying this technology without complete consideration for the risks that might arise from its use.</p>
<ul>
<li><p>Unexpected failures and emergent behaviour in a highly volatile environment like war presents very real concerns.</p></li>
<li><p>AI systems are vulnerable to new vectors of attack and the novel domain of Machine Learning Security is highly important to include in these discussions.</p></li>
</ul>
</li>
</ul>
<blockquote>
<div><p>My book <a class="reference external" href="https://atg-abhishek.github.io/actionable-ai-ethics">Actionable AI Ethics</a> walks through these ideas in practice.</p>
</div></blockquote>
<ul class="simple">
<li><p>The ability to use AI systems in warfare lends advanced capabilities to non-state actors who might not adhere to items like Article 36 that checks whether new weapons are consistent with the Geneva Convention posing an additional risk. Typically, state actors do follow these laws.</p></li>
<li><p>From a <em>policy perspective</em>, a tradeoff that comes up frequently is the benefit that such coordination efforts can have in terms of minimizing miscalculation of the other’s capabilities and reducing inadvertent escalation. But, this might also mean that we create more robust AI systems that are quicker and more effective in their deployments.</p></li>
</ul>
</div>
<div class="section" id="how-do-we-create-pragmatic-engagement">
<h3>How do we create pragmatic engagement?<a class="headerlink" href="#how-do-we-create-pragmatic-engagement" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p><strong>Developing a shared vernacular</strong>: I’ve pointed out in my previous work with a colleague published at the Oxford Internet Institute that there is a dire need to have consistency in how we discuss the risks from AI systems. Specifically, without consensus and shared understanding we risk talking <em>across</em> each other.</p>
<ul>
<li><p>Notably, the Chinese approach here has included societal impacts in addition to the technical considerations in the use of AI in the military.</p></li>
</ul>
</li>
<li><p><strong>Shared evaluation of each other’s work</strong>: Even in trying times of geopolitical tension, one can embark on carefully selected initiatives to translate and interpret work being done by others in an attempt to develop a shared understanding. Taking the example of the USSR-US collaboration on the Apollo-Soyuz project during the Cold War stands as an example of how diplomacy can be advanced through scientific endeavors.</p>
<ul>
<li><p>In particular, this has implications for the kind of collaboration that might take place between China and USA, the two major forces in the use of AI in a national security context. Translation of each other’s work will help avoid misunderstanding.</p></li>
</ul>
</li>
<li><p>Utilizing Track 2 and Track 1.5 mechanisms in addition to primary channels to achieve diplomacy is an effective approach to diffusing tensions and discussing policies and security considerations that might be mired amongst other issues in Track 1 discussions.</p></li>
</ul>
<div class="section" id="what-is-track-1-5-and-track-2">
<h4>What is Track 1.5 and Track 2?<a class="headerlink" href="#what-is-track-1-5-and-track-2" title="Permalink to this headline">¶</a></h4>
<p>At major policy negotiations and conferences, these <em>tracks</em> are venues where supplemental agendas are discussed, often with the presence of domain experts and those operating in assistance capacities to the official delegates.
It is an avenue for advancing goals like the ones being discussed here that are sometimes nascent and not as immediately included in the primary agendas of the gathering.</p>
</div>
</div>
<div class="section" id="actions-that-people-can-take">
<h3>Actions that people can take<a class="headerlink" href="#actions-that-people-can-take" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Creating shared standards for testing, evaluating, verifying, and validating (TEVV) of these systems to compare capabilities and limitations across deployments is essential.</p></li>
</ul>
<blockquote>
<div><p>From an AI lifecycle perspective, <strong>TEVV</strong> is something that is covered in the <a class="reference external" href="https://atg-abhishek.github.io/actionable-ai-ethics">Actionable AI Ethics book</a> for those who are looking to gain a deeper understanding of this concept.</p>
</div></blockquote>
<p>An example benefit of this would be in judging whether the systems are adequately able to separate military and civilian targets. Also, the degree to which they are able to assure confidence in their results.</p>
<ul class="simple">
<li><p>While the inclusion of AI into nuclear security can have benefits in terms of higher precision in targeting, etc. we must also be conscious of destabilization because of inherent uncertainty in the use of these systems. This further strengthens the case for effective TEVV approaches to be used and adopted across countries.</p></li>
<li><p>A shared understanding on the relative weighting of the <em>false positives</em> and <em>false negatives</em> by different regimes will also help to calibrate the abilities of the systems in their usage across different regions.</p></li>
</ul>
</div>
<div class="section" id="open-sky-revival-for-ai-systems">
<h3>Open sky revival for AI systems<a class="headerlink" href="#open-sky-revival-for-ai-systems" title="Permalink to this headline">¶</a></h3>
<p>While the <em>Open Sky treaty</em> has faced considerable flak from the policy community and a <a class="reference external" href="https://www.wsj.com/articles/trump-exits-open-skies-treaty-moves-to-discard-observation-planes-11606055371">recent announcement from the US</a> represents an unfortunate development in the space. But, in terms of soft enforcement and monitoring, it is an essential mechanism for accountability. It also serves to reinforce a more representative understanding of the capabilities and limitations of AI from different countries.</p>
</div>
<div class="section" id="better-communication">
<h3>Better communication<a class="headerlink" href="#better-communication" title="Permalink to this headline">¶</a></h3>
<p>In a field like AI that prides itself on open-source and open-access policies in terms of research and development, we ought to extend this to the field of policy as well.
There is some risk that such an initiative might be one-sided, but taking an iterative approach to building trust can assess the viability of such an approach.</p>
</div>
<div class="section" id="lessons-learned">
<h3>Lessons learned<a class="headerlink" href="#lessons-learned" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Sometimes bilateral sessions have points of friction that are hard to overcome, utilizing multilateral fora can help ease those points of friction.</p></li>
<li><p>Starting with small, concrete, tractable issues will help to incrementally build trust to tackle larger issues later on.</p></li>
<li><p>Gathering a diverse set of stakeholders, appropriate for the stage of conversation is important rather than having a blanket set of people to approach and talk to.</p></li>
<li><p>Having a high degree of transparency in the operation of these initiatives and their goals along with a <strong>firm expectation of reciprocity</strong> will also help in the success of these initiatives.</p></li>
<li><p>Mitigating the risks of counter-intelligence are also important, especially for those who are invited to these fora.</p></li>
<li><p>Track 2 conversations should become routine and tracking their efficacy through metrics and outcomes can help justify their existence rather than having them as one-off events.</p></li>
<li><p>Related to the above point, having tight feedback loops between Track 1 and other tracks will help to keep each other abreast of the relevant issues and their severity.</p></li>
<li><p>A discussion on the seriousness of issues, especially those that might not be raised at Track 1 in the service of achieving other goals shouldn’t deter their discussion in other tracks. This will be essential for places where for example there might be human rights implications, say in the case of persecution of Uighurs in China aided by the use of facial recognition technology.</p></li>
</ul>
</div>
<div class="section" id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h3>
<p>There are many shortcomings in the way AI safety is discussed at an international level at the moment and without more coordinated efforts that build on existing policymaking and negotiation instruments, we risk creating a fragmented ecosystem that can lead to unintended consequences in terms of assessing each other’s AI capabilities and mitigating the risks that arise from its use.</p>
</div>
<div class="section" id="what-does-this-mean-for-actionable-ai-ethics">
<h3>What does this mean for Actionable AI Ethics?<a class="headerlink" href="#what-does-this-mean-for-actionable-ai-ethics" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>As a practitioner, this means that we have a responsibility to communicate more clearly the impacts of our work to those who might be involved in policy making, both at a domestic and international level. Specifically, I envision working with others to create a shared commons, something like the <a class="reference external" href="https://montrealethics.ai/dictionary">Living Dictionary</a> that can help with this.</p></li>
<li><p>If you are invited to be a part of some of these <em>Track 1.5</em> and <em>Track 2</em> conversations, please do engage as they are great ways of making an impact by sharing the real capabilities and limitations of AI systems.</p></li>
</ul>
</div>
<div class="section" id="questions-that-i-am-exploring">
<h3>Questions that I am exploring<a class="headerlink" href="#questions-that-i-am-exploring" title="Permalink to this headline">¶</a></h3>
<p><strong>If you have answers to any of these questions, please <span class="xref myst">tweet</span> and let me know!</strong></p>
<ol class="simple">
<li><p>How can the policymaking community better tap into the network of practitioners to invite the appropriate stakeholders to these conversations?</p></li>
<li><p>What are the barriers for technical folks to understand some of the policy implications of their work?</p></li>
</ol>
</div>
<div class="section" id="potential-further-reading">
<h3>Potential further reading<a class="headerlink" href="#potential-further-reading" title="Permalink to this headline">¶</a></h3>
<p>A list of papers that I think might be interesting related to this paper.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.cambridge.org/core/journals/ethics-and-international-affairs/article/rising-powers-responsibility-and-international-society/76D5EC745B207058B331EBFE9409C6EE">Rising Powers, Responsibility, and International Society</a></p></li>
<li><p><a class="reference external" href="https://dl.acm.org/doi/10.1145/3407982.3408001">Understanding the Essence of Artificial Intelligence: Towards Ecological Safety of AI in Human Society</a></p></li>
</ul>
<p><em>Please note that this is a wish list of sorts and I haven’t read through the papers listed here unless specified otherwise (if I have read them, there will be a link from the entry to the page for that.)</em></p>
</div>
<div class="section" id="twitter-discussion">
<h3>Twitter discussion<a class="headerlink" href="#twitter-discussion" title="Permalink to this headline">¶</a></h3>
<p>I’ll write back here with interesting points that surface from the Twitter discussion.</p>
<p><em>If you have comments and would like to discuss more, please leave a <span class="xref myst">tweet here</span>.</em></p>
</div>
<div class="section" id="sign-up-for-the-newsletter">
<h3>Sign up for the newsletter<a class="headerlink" href="#sign-up-for-the-newsletter" title="Permalink to this headline">¶</a></h3>
<iframe src="https://actionableaiethics.substack.com/embed" width="480" height="320" style="border:1px solid #EEE; background:white;" frameborder="0" scrolling="no"></iframe>
<p>To stay up-to-date with the latest content in terms of what I am reading and thinking about, please subscribe to the <a class="reference external" href="https://actionableaiethics.substack.com">Actionable AI Ethics newsletter</a></p>
</div>
<div class="section" id="support-me-with-a-coffee">
<h3>Support me with a coffee<a class="headerlink" href="#support-me-with-a-coffee" title="Permalink to this headline">¶</a></h3>
<p>If you enjoy the content on this page, you can support my work by <a class="reference external" href="https://buymeacoffee.com/abhishekgupta">buying me a coffee</a></p>
<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="abhishekgupta" data-color="#FF5F5F" data-emoji=""  data-font="Cookie" data-text="Buy me a coffee" data-outline-color="#000000" data-font-color="#ffffff" data-coffee-color="#FFDD00" ></script></div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="american_war_machine.html" title="previous page">“Cool Projects” or “Expanding the Efficiency of the Murderous American War Machine?”</a>
    <a class='right-next' id="next-link" href="disability_bias_ai.html" title="next page">Disability, Bias, and AI</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Abhishek Gupta<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="_static/js/index.js"></script>
    
  </body>
</html>