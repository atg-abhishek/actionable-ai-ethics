

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>“Cool Projects” or “Expanding the Efficiency of the Murderous American War Machine?” &#8212; Actionable AI Ethics</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-dropdown.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="https://atg-abhishek.github.io/actionable-ai-ethics/american_war_machine.html" />
    <link rel="shortcut icon" href="_static/abhishek.png"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Automating informality: On AI and labour in the global South" href="automating_informality.html" />
    <link rel="prev" title="Others" href="others.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">


<!-- Opengraph tags -->
<meta property="og:url"         content="https://atg-abhishek.github.io/actionable-ai-ethics/american_war_machine.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="“Cool Projects” or “Expanding the Efficiency of the Murderous American War Machine?”" />
<meta property="og:description" content="“Cool Projects” or “Expanding the Efficiency of the Murderous American War Machine?”  Authors: Catherine Aiken, Rebecca Kagan, Michael Page  Paper link  Summary" />
<meta property="og:image"       content="https://atg-abhishek.github.io/actionable-ai-ethics/_static/abhishek.png" />

<meta name="twitter:card" content="summary" />


  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/abhishek.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Actionable AI Ethics</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Welcome to Actionable AI Ethics
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Papers
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="papers.html">
   Papers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="privacy.html">
   Privacy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="bias_and_fairness.html">
   Bias and Fairness
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="traceability_and_auditability.html">
   Traceability and Auditability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="interpretability_and_explainability.html">
   Interpretability and Explainability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="machine_learning_security.html">
   Machine Learning Security
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="others.html">
   Others
  </a>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     “Cool Projects” or “Expanding the Efficiency of the Murderous American War Machine?”
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="automating_informality.html">
     Automating informality: On AI and labour in the global South
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ai_safety_great_powers.html">
     AI Safety, Security, and Stability Among Great Powers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="algorithmic_content_moderation.html">
     Algorithmic content moderation: Technical and political challenges in the automation of platform governance
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Tools
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="tools.html">
   AI Ethics Tool of the Week
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Books
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="books.html">
   Books
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  You can support this work by <a href="https://buymeacoffee.com/abhishekgupta">buying me a coffee!</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/american_war_machine.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary">
   Summary
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-line-summary">
     One-line summary
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#key-findings">
     Key findings
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-is-the-key-problem-this-study-is-trying-to-address">
     What is the key problem this study is trying to address?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#survey-questions">
     Survey questions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#discussion-of-results">
     Discussion of results
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conclusion">
     Conclusion
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#what-does-this-mean-for-actionable-ai-ethics">
     What does this mean for Actionable AI Ethics?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#questions-that-i-am-exploring">
     Questions that I am exploring
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#potential-further-reading">
     Potential further reading
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#twitter-discussion">
     Twitter discussion
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sign-up-for-the-newsletter">
     Sign up for the newsletter
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support-me-with-a-coffee">
     Support me with a coffee
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="cool-projects-or-expanding-the-efficiency-of-the-murderous-american-war-machine">
<h1>“Cool Projects” or “Expanding the Efficiency of the Murderous American War Machine?”<a class="headerlink" href="#cool-projects-or-expanding-the-efficiency-of-the-murderous-american-war-machine" title="Permalink to this headline">¶</a></h1>
<p><strong>Authors</strong>: Catherine Aiken, Rebecca Kagan, Michael Page</p>
<p><a class="reference external" href="https://cset.georgetown.edu/research/cool-projects-or-expanding-the-efficiency-of-the-murderous-american-war-machine/">Paper link</a></p>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<div class="section" id="one-line-summary">
<h3>One-line summary<a class="headerlink" href="#one-line-summary" title="Permalink to this headline">¶</a></h3>
<p>This research study seeks to glean whether there is indeed an adversarial dynamic between the tech industry and the Department of Defense (DoD) and other US government agencies. It finds that there is wide variability in perception that the tech industry has of the DoD, and willingness to work depends on the area of work and prior exposure to funding from and work of the DoD.</p>
<iframe src="https://actionableaiethics.substack.com/embed" width="480" height="320" style="border:1px solid #EEE; background:white;" frameborder="0" scrolling="no"></iframe>
<p>If you enjoy the content on this page, you can support my work by <a class="reference external" href="https://buymeacoffee.com/abhishekgupta">buying me a coffee</a></p>
<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="abhishekgupta" data-color="#FF5F5F" data-emoji=""  data-font="Cookie" data-text="Buy me a coffee" data-outline-color="#000000" data-font-color="#ffffff" data-coffee-color="#FFDD00" ></script>
</div>
<div class="section" id="key-findings">
<h3>Key findings<a class="headerlink" href="#key-findings" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Most AI professionals are actually positive or neutral on working with the DoD. <strong>This is in stark contrast to what the common media portrayal is of the attitudes of workers in the tech industry.</strong></p></li>
<li><p>Doing good and working in interesting research areas were the most compelling reasons to engage with the DoD.</p></li>
<li><p>Discomfort primarily arose from lack of clarity on how the DoD might use their work and potentially using the work to cause harm.</p></li>
<li><p><em>Unsurprisingly</em>, people were more willing to work on humanitarian projects compared to war efforts or back-office applications (<em>the back office attitude was surprising to me</em>).</p></li>
<li><p>If the funding provided by the DoD is used solely for basic research, a lot of people were willing to engage.</p></li>
<li><p>Academia and their own employers got the highest trust ratings when it came to whether AI will be developed with the public interest at heart.</p></li>
<li><p>Those that had prior exposure to the funding and work from the DoD has more positive viewpoints on the DoD. <strong>I’ll talk a bit more about this later, but I think there is an unaddressed bias that might need to be thought about in this context.</strong></p></li>
</ul>
<p>Ultimately, there isn’t a binary framing that characterizes the relationship between the tech industry and the DoD as is commonly portrayed in the media, and depending on the context, we get varying results in terms of the willingness of people to engage with this kind of work.</p>
</div>
<div class="section" id="what-is-the-key-problem-this-study-is-trying-to-address">
<h3>What is the key problem this study is trying to address?<a class="headerlink" href="#what-is-the-key-problem-this-study-is-trying-to-address" title="Permalink to this headline">¶</a></h3>
<p>There are many conflicting narratives on the willingness to engage and attitudes towards the DoD from the tech industry.
To clarify these and gain a better understanding for what the reality is and which factors shape that will help to better bridge the gaps between US government agencies and the tech industry.</p>
<p>The DoD in particular has the ability to drive large-scale changes by virtue of its funding and market-making power which means that there are a lot of scientific advances that academia and industry might be unwilling to investigate that if funded by the DoD (when people are willing to engage with them) can lead to large societal benefits.
Essentially, having a productive, open, and honest dialogue between the two is essential to leverage the potential opportunities.</p>
</div>
<div class="section" id="survey-questions">
<h3>Survey questions<a class="headerlink" href="#survey-questions" title="Permalink to this headline">¶</a></h3>
<p>The questions were centred around trying to elicit the attitudes that people had towards the DoD, what their response would be to a hypothetical project in terms of engagement and employer relationship, what might be some factors that can shift their perceptions, and finally their understanding and perception of the different US agencies and trust in the political instruments in the US.</p>
<ul class="simple">
<li><p>A caveat that the authors point out is that they had a fairly low response rate (~4%) to the survey that they used and as such don’t provide guarantees on the representativeness of the general population and call for further research to build upon the results that they obtain in this study.</p></li>
<li><p>The study also ended up sourcing practitioners who self-identified as AI practitioners online and were mostly from the major tech hubs like Boston, SF, Seattle, etc. so perhaps not fully representative of all the places where such collaborations might be taking place.</p></li>
</ul>
</div>
<div class="section" id="discussion-of-results">
<h3>Discussion of results<a class="headerlink" href="#discussion-of-results" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>One of the most interesting findings for me from this study was the vast difference in positive perception of the DoD when people had prior exposure to working with them.</p>
<ul>
<li><p>This might be a case where people genuinely through their interactions with the DoD found the work to be highly meaningful and to buck the narrative that most applications of AI by the DoD are war-related with the potential to cause harm.</p></li>
<li><p>This might also be influenced by the fact that participants normalized such work, even if there were some ethical consequences, by virtue of repeated exposure and working on it over time.</p></li>
</ul>
</li>
<li><p>The ability to work on big, cutting-edge research and the potential to do a lot of good through such engagements was one of the <strong>most compelling reasons</strong> to engage with the DoD.</p>
<ul>
<li><p>Another consideration is that the DoD might be able to provide access to technology and data that might otherwise be inaccessible that can help surface insights pushing the envelope.</p></li>
</ul>
</li>
<li><p>The <strong>most prominent concern</strong> identified by the responders was the potential for misuse of the research, a lack of ethics, and harm that might be inflicted on people through the advances made in such collaborations.</p>
<ul>
<li><p>Alleviating these through transparent and robust governance can help both parties, especially researchers building more trust in the DoD.</p></li>
<li><p>Specifying outcomes and making sure that those are adhered to can be a way that might help alleviate some of these concerns.</p></li>
<li><p>The lack of transparency sometimes in being able to publish results, or not having complete control over the direction of the research was cited as a reason for not engaging.</p></li>
</ul>
</li>
<li><p>The general views that people hold of the DoD greatly impacted in both the positive and the negative reasons that they found compelling in a potential engagement. Thus, there is a strong prior effect that can shape the willingness of actors from the tech industry to engage.</p></li>
<li><p>While one might imagine that willingness might be increased by framing the work in the context of threats to the US from foreign adversaries, this wasn’t something that was indicated by the respondents to the survey.</p></li>
<li><p>Most people that responded weren’t aware of the DoD ethical AI principles that were published.</p>
<ul>
<li><p>This is perhaps something that needs redressal so that we have balanced discussions on the impact of technologies and what measures are being used to mitigate harmful consequences.</p></li>
</ul>
</li>
<li><p><strong>Differential motivations</strong> in the responders was an important finding from this study.</p>
<ul>
<li><p>When people had a positive perception, the potential to mitigate foreign threats to the safety of the US was a strong motivating factor.</p></li>
<li><p>When people had a negative perception, engaging in non-combat related work was a strong motivating factor.</p></li>
<li><p>There also wasn’t <em>unwillingness as the default</em> amongst AI practitioners, something that is probably miscommunicated most often in popular media.</p></li>
</ul>
</li>
<li><p>In terms of <strong>actions that employees would take</strong> when presented with an opportunity to engage with the DoD, in the case of the hypothetical humanitarian project, most would choose to engage. In the case of the battlefield project, most would choose to not engage.</p>
<ul>
<li><p>An insight that was interesting here was that the frequency of people proactively supporting projects that they believed in was <strong>higher</strong> than that of those who actively condemned the projects that they didn’t believe in.</p></li>
</ul>
</li>
<li><p>In terms of the <strong>discussions around lethal autonomous weapons</strong>, most people were somewhat familiar with the issues in the larger ecosystem, but not specifically as they relate to the DoD.</p></li>
<li><p>In choosing to work on something or not, a lot of professionals took into consideration the social impact of their work which is a good indication for the healthiness of the ecosystem.</p></li>
<li><p>In terms of <strong>trust</strong>, intergovernmental organizations and the EU ranked higher than US government agencies and tech companies. The Chinese government received the least amount of trust from the respondents.</p>
<ul>
<li><p>These perceptions are not without flaws: I think that the role that media plays in how it portrays each of the actors has a huge impact.</p></li>
<li><p>Trust in national governments was high when it came to who should be entrusted with the responsibility to manage the consequences of AI.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="conclusion">
<h3>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h3>
<p>My takeaway from the study was that we need to have more granular and informed discussions when it comes to the relationship between the tech industry and government agencies. Ill-informed characterizations, propagated by media outlets, sometimes based on anecdotal evidence have the potential to do tremendous harm by creating self-fulfilling prophecies that strain the relationship between the two.</p>
</div>
<div class="section" id="what-does-this-mean-for-actionable-ai-ethics">
<h3>What does this mean for Actionable AI Ethics?<a class="headerlink" href="#what-does-this-mean-for-actionable-ai-ethics" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Straying away from research with government agencies just based on perceptions that you have formed from the media discourse are inadequate grounds for making a decision. Active recognition of your own biases and searching for information to gain a balanced understanding will be essential to support your claims to engage or not to engage within your organization.</p></li>
</ul>
</div>
<div class="section" id="questions-that-i-am-exploring">
<h3>Questions that I am exploring<a class="headerlink" href="#questions-that-i-am-exploring" title="Permalink to this headline">¶</a></h3>
<p><strong>If you have answers to any of these questions, please <span class="xref myst">tweet</span> and let me know!</strong></p>
<ol class="simple">
<li><p>Why is there such a high-level of miscommunication in popular media that is debunked to a certain extent by this study?</p></li>
<li><p>How can we do better to have balanced conversations around DoD-supported research that isn’t polarized between two extremes?</p></li>
</ol>
</div>
<div class="section" id="potential-further-reading">
<h3>Potential further reading<a class="headerlink" href="#potential-further-reading" title="Permalink to this headline">¶</a></h3>
<p>A list of papers that I think might be interesting related to this paper.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.tandfonline.com/doi/abs/10.1080/23738871.2019.1701693?journalCode=rcyb20">The AI-cyber nexus: implications for military escalation, deterrence and strategic stability</a></p></li>
<li><p><a class="reference external" href="https://link.springer.com/chapter/10.1007%2F978-3-030-51110-4_11">Miltary uses of AI</a></p></li>
</ul>
<p><em>Please note that this is a wish list of sorts and I haven’t read through the papers listed here unless specified otherwise (if I have read them, there will be a link from the entry to the page for that.)</em></p>
</div>
<div class="section" id="twitter-discussion">
<h3>Twitter discussion<a class="headerlink" href="#twitter-discussion" title="Permalink to this headline">¶</a></h3>
<p>I’ll write back here with interesting points that surface from the Twitter discussion.</p>
<p><em>If you have comments and would like to discuss more, please leave a <span class="xref myst">tweet here</span>.</em></p>
</div>
<div class="section" id="sign-up-for-the-newsletter">
<h3>Sign up for the newsletter<a class="headerlink" href="#sign-up-for-the-newsletter" title="Permalink to this headline">¶</a></h3>
<iframe src="https://actionableaiethics.substack.com/embed" width="480" height="320" style="border:1px solid #EEE; background:white;" frameborder="0" scrolling="no"></iframe>
<p>To stay up-to-date with the latest content in terms of what I am reading and thinking about, please subscribe to the <a class="reference external" href="https://actionableaiethics.substack.com">Actionable AI Ethics newsletter</a></p>
</div>
<div class="section" id="support-me-with-a-coffee">
<h3>Support me with a coffee<a class="headerlink" href="#support-me-with-a-coffee" title="Permalink to this headline">¶</a></h3>
<p>If you enjoy the content on this page, you can support my work by <a class="reference external" href="https://buymeacoffee.com/abhishekgupta">buying me a coffee</a></p>
<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="abhishekgupta" data-color="#FF5F5F" data-emoji=""  data-font="Cookie" data-text="Buy me a coffee" data-outline-color="#000000" data-font-color="#ffffff" data-coffee-color="#FFDD00" ></script></div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="others.html" title="previous page">Others</a>
    <a class='right-next' id="next-link" href="automating_informality.html" title="next page">Automating informality: On AI and labour in the global South</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Abhishek Gupta<br/>
        
            &copy; Copyright 2021.<br/>
          <div class="extra_footer">
            Making Responsible AI the Norm rather than the Exception
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="_static/js/index.js"></script>
    
  </body>
</html>